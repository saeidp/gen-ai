{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ecb0c6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ff5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PIP_INDEX_URL=https://pypi.org/simple\n",
    "%pip install -U langgraph langsmith\n",
    "%pip install -U \"langchain[aws]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72fb79",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c5c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model # type: ignore\n",
    "\n",
    "# Follow the steps here to configure your credentials:\n",
    "# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\n",
    "\n",
    "llm = init_chat_model(\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    model_provider=\"bedrock_converse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1417f22b",
   "metadata": {},
   "source": [
    "# Create a StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START # type: ignore\n",
    "from langgraph.graph.message import add_messages # type: ignore\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    print(\"Chatbot invoked:\", state[\"messages\"])\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24d7c1",
   "metadata": {},
   "source": [
    "# Visualize the graph (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f819f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf60ff4",
   "metadata": {},
   "source": [
    "# Run the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d5599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hello\n",
      "Chatbot invoked [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='0f41ddc1-090c-4cfb-ab57-d6106a121f35')]\n",
      "value_messages: [AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '95ec63aa-3915-4af0-bb3f-050eacf11e96', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 14 May 2025 03:28:31 GMT', 'content-type': 'application/json', 'content-length': '214', 'connection': 'keep-alive', 'x-amzn-requestid': '95ec63aa-3915-4af0-bb3f-050eacf11e96'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [309]}, 'model_name': 'anthropic.claude-3-haiku-20240307-v1:0'}, id='run--0a32e8fd-75e1-4b04-98cd-e4fade0a10f1-0', usage_metadata={'input_tokens': 8, 'output_tokens': 12, 'total_tokens': 20, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]\n",
      "Assistant: Hello! How can I assist you today?\n",
      "User: how are you\n",
      "Chatbot invoked [HumanMessage(content='how are you', additional_kwargs={}, response_metadata={}, id='57411ce1-7414-4615-b306-ed2dd76a3673')]\n",
      "value_messages: [AIMessage(content=\"I'm doing well, thanks for asking! As an AI assistant, I don't experience emotions the same way humans do, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '5fb5e4a5-bd0a-49a2-b0bb-66b17f257939', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 14 May 2025 03:28:58 GMT', 'content-type': 'application/json', 'content-length': '409', 'connection': 'keep-alive', 'x-amzn-requestid': '5fb5e4a5-bd0a-49a2-b0bb-66b17f257939'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1035]}, 'model_name': 'anthropic.claude-3-haiku-20240307-v1:0'}, id='run--3dfd5901-487a-4b27-8bfd-020c2dbcb6ba-0', usage_metadata={'input_tokens': 10, 'output_tokens': 54, 'total_tokens': 64, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]\n",
      "Assistant: I'm doing well, thanks for asking! As an AI assistant, I don't experience emotions the same way humans do, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n",
      "User: q\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        print(\"User: \" + user_input)\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        # user_input = \"What do you know about LangGraph?\"\n",
    "        # print(\"User: \" + user_input)\n",
    "        # stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f0e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
