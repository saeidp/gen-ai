{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427091c4",
   "metadata": {},
   "source": [
    "Use prebuilts:  \n",
    "BasicToolNode is replaced with the prebuilt ToolNode   \n",
    "route_tools is replaced with the prebuilt tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb9e68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded: tvly...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load from .env file\n",
    "\n",
    "api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "print(\"API key loaded:\", api_key[:4] + \"...\" if api_key else \"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4332d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model # type: ignore\n",
    "\n",
    "# Follow the steps here to configure your credentials:\n",
    "# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\n",
    "\n",
    "llm = init_chat_model(\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    model_provider=\"bedrock_converse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b13e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e6311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What do you know about LangGraph?\n",
      "Assistant: [{'type': 'text', 'text': 'Here is what I found about LangGraph:'}, {'type': 'tool_use', 'name': 'tavily_search', 'input': {'query': 'LangGraph', 'search_depth': 'advanced'}, 'id': 'tooluse_WIElCnV6QjewetSw_or8Sw'}]\n",
      "Assistant: {\"query\": \"LangGraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.ibm.com/think/topics/langgraph\", \"title\": \"What is LangGraph? - IBM\", \"content\": \"LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\nLLM applications: By using LangGraphâ€™s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.\", \"score\": 0.9353998, \"raw_content\": null}, {\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"title\": \"LangGraph Quickstart - GitHub Pages\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\", \"score\": 0.9328032, \"raw_content\": null}], \"response_time\": 1.93}\n",
      "Assistant: Based on the search results, here's what I've learned about LangGraph:\n",
      "\n",
      "LangGraph is an open source AI agent framework created by LangChain. It is designed to help build, deploy and manage complex generative AI agent workflows. Some key points about LangGraph:\n",
      "\n",
      "- It uses a graph-based architecture to model and manage the relationships between various components of an AI agent workflow. This allows for scalable and efficient management of AI systems.\n",
      "\n",
      "- It provides tools and libraries for creating, running and optimizing large language models (LLMs) in a more structured way compared to standalone LLMs.\n",
      "\n",
      "- It enables building more sophisticated AI models that can learn and improve over time through features like reflection on past actions and feedback.\n",
      "\n",
      "- LangGraph is particularly useful for developing agent-based systems and applications that leverage LLMs, such as robotics, autonomous vehicles, video games, and personalized AI assistants.\n",
      "\n",
      "- Some example use cases mentioned include Norwegian Cruise Line using LangGraph to build and refine guest-facing AI solutions.\n",
      "\n",
      "So in summary, LangGraph is a framework that aims to simplify the development and management of complex, multi-agent AI systems built on top of large language models. It provides a structured, graph-based approach to coordinating different AI components and workflows.\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241124ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
