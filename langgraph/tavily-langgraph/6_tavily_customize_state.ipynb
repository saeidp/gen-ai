{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ef445d",
   "metadata": {},
   "source": [
    "### In this Lab you will add additional fields to the state to define complex behavior without relying on the message list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab69f694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded: tvly...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load from .env file\n",
    "\n",
    "api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "print(\"API key loaded:\", api_key[:4] + \"...\" if api_key else \"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48200c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model # type: ignore\n",
    "\n",
    "# Follow the steps here to configure your credentials:\n",
    "# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\n",
    "\n",
    "llm = init_chat_model(\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    model_provider=\"bedrock_converse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb5cb4",
   "metadata": {},
   "source": [
    "### 1- Add keys to the state and update the state inside the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e87d93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools =[tool, human_assistance]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # Because we will be interrupting during tool execution,\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume.\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18254f2d",
   "metadata": {},
   "source": [
    "### 2- Prompt the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ef708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'tool_use', 'name': 'tavily_search', 'input': {'query': 'when was LangGraph released', 'search_depth': 'advanced'}, 'id': 'tooluse_qsHzXSQoR6qULvuRu3E0bw'}]\n",
      "Tool Calls:\n",
      "  tavily_search (tooluse_qsHzXSQoR6qULvuRu3E0bw)\n",
      " Call ID: tooluse_qsHzXSQoR6qULvuRu3E0bw\n",
      "  Args:\n",
      "    query: when was LangGraph released\n",
      "    search_depth: advanced\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"when was LangGraph released\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://juancalvoferrandiz.medium.com/discovering-langgraph-paving-the-path-to-reliable-ai-systems-a9cd348c9d57\", \"title\": \"Discovering LangGraph: Paving the Path to Reliable AI Systems\", \"content\": \"While Langchainâ€™s Expression Language provides a declarative way to create custom chains as DAGs, many real-world use cases, such as refining search results or iterating on complex calculations, demand the adaptability of cycles and loops. This is where LangGraph shines. LangGraph was released in mid-January 2024. It empowers us to define state machine architectures as graphs. This provides a more visual and intuitive layer of abstraction to design how AI systems should dynamically process\", \"score\": 0.9067276, \"raw_content\": null}, {\"url\": \"https://www.marktechpost.com/2024/08/03/langchain-introduces-langgraph-studio-the-first-agent-ide-for-visualizing-interacting-with-and-debugging-complex-agentic-applications/\", \"title\": \"LangChain Introduces LangGraph Studio: The First Agent IDE for ...\", \"content\": \"LangGraph, launched in January 2023, is a highly controllable, low-level orchestration framework for building agentic applications. Since its inception, it has undergone significant improvements, leading to a stable 0.1 release in June. LangGraph features a persistence layer enabling human-in-the-loop interactions and excels at building complex applications requiring domain-specific cognitive architecture. [...] Published Time: 2024-08-04T05:10:57+00:00\\nLangChain Introduces LangGraph Studio: The First Agent IDE for Visualizing, Interacting with, and Debugging Complex Agentic Applications - MarkTechPost\\n===============\\nDiscordLinkedinRedditTwitter\\n\\nHome\\n\\nAI Research News\\n\\nLLMs\\nSmall Language Model\\nML News\\nComputer Vision\\nFederated Learning\\nReinforcement Learning\\nNatural Language Processing\\n\\n\\n\\nAI Agents\\n\\n\\nNew Releases\\n\\nOpen Source AI\\n\\n\\n\\nTutorials\\n\\nAI Magazines\\nminiCON 2025\\nðŸ”¥ Promotion [...] August 3, 2024\\nLarge Language Models (LLMs) have revolutionized the development of agentic applications, necessitating the evolution of tooling for efficient development. To tackle this issue, Langchain introducedLangGraph Studioas the first integrated development environment (IDE) specifically designed for agent development, which isnow available in open beta.\", \"score\": 0.84246206, \"raw_content\": null}], \"response_time\": 1.44}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'Based on the search results, it appears that LangGraph was released in mid-January 2024. The first result mentions that \"LangGraph was released in mid-January 2024\" and provides some context around what LangGraph is and how it relates to Langchain. The second result also references the release of LangGraph, saying it launched in January 2023 and had a stable 0.1 release in June.'}, {'type': 'tool_use', 'name': 'human_assistance', 'input': {'name': 'Human', 'birthday': '1980-01-01'}, 'id': 'tooluse_DeC5eXxGQfiGeH5pgxqPtQ'}]\n",
      "Tool Calls:\n",
      "  human_assistance (tooluse_DeC5eXxGQfiGeH5pgxqPtQ)\n",
      " Call ID: tooluse_DeC5eXxGQfiGeH5pgxqPtQ\n",
      "  Args:\n",
      "    name: Human\n",
      "    birthday: 1980-01-01\n"
     ]
    }
   ],
   "source": [
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b50289",
   "metadata": {},
   "source": [
    "We've hit the interrupt in the human_assistance tool again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718fd84c",
   "metadata": {},
   "source": [
    "The chatbot failed to identify the correct date, so supply it with information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f76c0b",
   "metadata": {},
   "source": [
    "### 3- Add human assistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3698dd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'Based on the search results, it appears that LangGraph was released in mid-January 2024. The first result mentions that \"LangGraph was released in mid-January 2024\" and provides some context around what LangGraph is and how it relates to Langchain. The second result also references the release of LangGraph, saying it launched in January 2023 and had a stable 0.1 release in June.'}, {'type': 'tool_use', 'name': 'human_assistance', 'input': {'name': 'Human', 'birthday': '1980-01-01'}, 'id': 'tooluse_DeC5eXxGQfiGeH5pgxqPtQ'}]\n",
      "Tool Calls:\n",
      "  human_assistance (tooluse_DeC5eXxGQfiGeH5pgxqPtQ)\n",
      " Call ID: tooluse_DeC5eXxGQfiGeH5pgxqPtQ\n",
      "  Args:\n",
      "    name: Human\n",
      "    birthday: 1980-01-01\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it, thank you for the correction. Based on the additional information provided, it seems LangGraph was released on January 17, 2024. I will update my knowledge.\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d574ad7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cfb581",
   "metadata": {},
   "source": [
    "### 4- Manually update the state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51891ef8",
   "metadata": {},
   "source": [
    "LangGraph gives a high degree of control over the application state. For instance, at any point (including when interrupted), you can manually override a key using graph.update_state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c93c6b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f039bbd-4ded-617a-8006-800bb895157b'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492bfae",
   "metadata": {},
   "source": [
    "### 5- View the new value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6990ec69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph (library)', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
