{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Advanced processing of Strands Agents Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strands Agents allows you to intercept and process events as they happen during agent execution using two methods: \n",
    "    \n",
    "- **Async iterators**: ideal for asynchronous frameworks like FastAPI, aiohttp, or Django Channels. For these environments, the SDK offers the `stream_async` method which returns an asynchronous iterator. \n",
    "- **Callback handlers**: allow you to intercept and process events as they happen during agent execution. This enables real-time monitoring, custom output formatting, and integration with external systems.\n",
    "\n",
    "In this example, we will show you how to use both methods to handle calls on your agent\n",
    "\n",
    "\n",
    "## Agent Details\n",
    "<div style=\"float: left; margin-right: 20px; \">\n",
    "    \n",
    "|Feature             |Description                                        |\n",
    "|--------------------|---------------------------------------------------|\n",
    "|Feature used        |async iterators, callback handlers                 |\n",
    "|Agent Structure     |single agent architecture                          |\n",
    "|Native tools used   |calculator                                         |\n",
    "|Custom tools created|Weather forecast                                   |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "<div style=\"text-align:left;\">\n",
    "    <img src=\"./images/architecture.png\" width=\"65%\" />\n",
    "</div>\n",
    "\n",
    "## Key Features\n",
    "* Async Iterators for Streaming\n",
    "* Callback Handlers\n",
    "\n",
    "\n",
    "## Setup and prerequisites\n",
    "\n",
    "### Prerequisites\n",
    "* Python 3.10+\n",
    "* AWS account\n",
    "* Anthropic Claude 3.7 enabled on Amazon Bedrock\n",
    "\n",
    "Let's now install the requirement packages for our Strands Agent Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing pre-requisites\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dependency packages\n",
    "\n",
    "Now let's import the dependency packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import httpx\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import StreamingResponse\n",
    "from pydantic import BaseModel\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 - Async Iterators for Streaming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strands Agents provides support for asynchronous iterators through the `stream_async` method, enabling real-time streaming of agent responses in asynchronous environments like web servers, APIs, and other async applications.\n",
    "\n",
    "Since we are show casing this example in a notebook, we need to apply `nest_asyncio` to allow nested use of `asyncio.run` and `loop.run_until_complete`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and invoking agent with stream_async\n",
    "\n",
    "Let's now create our agent with a built-in calculator tool and no `callback_handler`. We will use the `stream_async` method to iteract over the streamed agent events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_338769/3892389870.py:5: UserWarning: Invalid configuration parameters: ['inference_profile_arn', 'provider', 'region'].\n",
      "Valid parameters are: ['additional_args', 'additional_request_fields', 'additional_response_field_paths', 'cache_prompt', 'cache_tools', 'guardrail_id', 'guardrail_redact_input', 'guardrail_redact_input_message', 'guardrail_redact_output', 'guardrail_redact_output_message', 'guardrail_stream_processing_mode', 'guardrail_trace', 'guardrail_version', 'include_tool_result_status', 'max_tokens', 'model_id', 'stop_sequences', 'streaming', 'temperature', 'top_p'].\n",
      "\n",
      "See https://github.com/strands-agents/sdk-python/issues/815\n",
      "  model = BedrockModel(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init_event_loop': True}\n",
      "{'start': True}\n",
      "{'start_event_loop': True}\n"
     ]
    },
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the ConverseStream operation: Invocation of model ID anthropic.claude-haiku-4-5-20251001-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     24\u001b[39m         \u001b[38;5;28mprint\u001b[39m(event)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Run the agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_streaming_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py:306\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    304\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    308\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    309\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mprocess_streaming_response\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_streaming_response\u001b[39m():\n\u001b[32m     22\u001b[39m     agent_stream = agent.stream_async(\u001b[33m\"\u001b[39m\u001b[33mCalculate 2+2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agent_stream:\n\u001b[32m     24\u001b[39m         \u001b[38;5;28mprint\u001b[39m(event)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/agent/agent.py:581\u001b[39m, in \u001b[36mAgent.stream_async\u001b[39m\u001b[34m(self, prompt, **kwargs)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    579\u001b[39m     events = \u001b[38;5;28mself\u001b[39m._run_loop(messages, invocation_state=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    582\u001b[39m         event.prepare(invocation_state=kwargs)\n\u001b[32m    584\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m event.is_callback_event:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/agent/agent.py:619\u001b[39m, in \u001b[36mAgent._run_loop\u001b[39m\u001b[34m(self, messages, invocation_state)\u001b[39m\n\u001b[32m    617\u001b[39m \u001b[38;5;66;03m# Execute the event loop cycle with retry logic for context limits\u001b[39;00m\n\u001b[32m    618\u001b[39m events = \u001b[38;5;28mself\u001b[39m._execute_event_loop_cycle(invocation_state)\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    620\u001b[39m     \u001b[38;5;66;03m# Signal from the model provider that the message sent by the user should be redacted,\u001b[39;00m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# likely due to a guardrail.\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    623\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(event, ModelStreamChunkEvent)\n\u001b[32m    624\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m event.chunk\n\u001b[32m    625\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m event.chunk.get(\u001b[33m\"\u001b[39m\u001b[33mredactContent\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    626\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m event.chunk[\u001b[33m\"\u001b[39m\u001b[33mredactContent\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mredactUserContentMessage\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    627\u001b[39m     ):\n\u001b[32m    628\u001b[39m         \u001b[38;5;28mself\u001b[39m.messages[-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m] = [\n\u001b[32m    629\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(event.chunk[\u001b[33m\"\u001b[39m\u001b[33mredactContent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mredactUserContentMessage\u001b[39m\u001b[33m\"\u001b[39m])}\n\u001b[32m    630\u001b[39m         ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/agent/agent.py:658\u001b[39m, in \u001b[36mAgent._execute_event_loop_cycle\u001b[39m\u001b[34m(self, invocation_state)\u001b[39m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    653\u001b[39m     \u001b[38;5;66;03m# Execute the main event loop cycle\u001b[39;00m\n\u001b[32m    654\u001b[39m     events = event_loop_cycle(\n\u001b[32m    655\u001b[39m         agent=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    656\u001b[39m         invocation_state=invocation_state,\n\u001b[32m    657\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    659\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ContextWindowOverflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    662\u001b[39m     \u001b[38;5;66;03m# Try reducing the context size and retrying\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/event_loop/event_loop.py:110\u001b[39m, in \u001b[36mevent_loop_cycle\u001b[39m\u001b[34m(agent, invocation_state)\u001b[39m\n\u001b[32m    107\u001b[39m invocation_state[\u001b[33m\"\u001b[39m\u001b[33mevent_loop_cycle_span\u001b[39m\u001b[33m\"\u001b[39m] = cycle_span\n\u001b[32m    109\u001b[39m model_events = _handle_model_execution(agent, cycle_span, cycle_trace, invocation_state, tracer)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m model_event \u001b[38;5;129;01min\u001b[39;00m model_events:\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_event, ModelStopReason):\n\u001b[32m    112\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m model_event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/event_loop/event_loop.py:316\u001b[39m, in \u001b[36m_handle_model_execution\u001b[39m\u001b[34m(agent, cycle_span, cycle_trace, invocation_state, tracer)\u001b[39m\n\u001b[32m    314\u001b[39m                 \u001b[38;5;28;01myield\u001b[39;00m EventLoopThrottleEvent(delay=current_delay)\n\u001b[32m    315\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# Add message in trace and mark the end of the stream messages trace\u001b[39;00m\n\u001b[32m    320\u001b[39m     stream_trace.add_message(message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/event_loop/event_loop.py:264\u001b[39m, in \u001b[36m_handle_model_execution\u001b[39m\u001b[34m(agent, cycle_span, cycle_trace, invocation_state, tracer)\u001b[39m\n\u001b[32m    261\u001b[39m tool_specs = agent.tool_registry.get_all_tool_specs()\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m stream_messages(agent.model, agent.system_prompt, agent.messages, tool_specs):\n\u001b[32m    265\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    267\u001b[39m     stop_reason, message, usage, metrics = event[\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/event_loop/streaming.py:351\u001b[39m, in \u001b[36mstream_messages\u001b[39m\u001b[34m(model, system_prompt, messages, tool_specs)\u001b[39m\n\u001b[32m    348\u001b[39m messages = remove_blank_messages_content_text(messages)\n\u001b[32m    349\u001b[39m chunks = model.stream(messages, tool_specs \u001b[38;5;28;01mif\u001b[39;00m tool_specs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, system_prompt)\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m process_stream(chunks):\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/event_loop/streaming.py:308\u001b[39m, in \u001b[36mprocess_stream\u001b[39m\u001b[34m(chunks)\u001b[39m\n\u001b[32m    305\u001b[39m usage: Usage = Usage(inputTokens=\u001b[32m0\u001b[39m, outputTokens=\u001b[32m0\u001b[39m, totalTokens=\u001b[32m0\u001b[39m)\n\u001b[32m    306\u001b[39m metrics: Metrics = Metrics(latencyMs=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m ModelStreamChunkEvent(chunk=chunk)\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmessageStart\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m chunk:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/models/bedrock.py:625\u001b[39m, in \u001b[36mBedrockModel.stream\u001b[39m\u001b[34m(self, messages, tool_specs, system_prompt, tool_choice, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m task\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/futures.py:286\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py:375\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    377\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    378\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py:306\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    304\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    308\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    309\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/threads.py:25\u001b[39m, in \u001b[36mto_thread\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m ctx = contextvars.copy_context()\n\u001b[32m     24\u001b[39m func_call = functools.partial(ctx.run, func, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func_call)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/futures.py:286\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py:375\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    377\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    378\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-linux-x86_64-gnu/lib/python3.13/concurrent/futures/thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/opentelemetry/instrumentation/threading/__init__.py:171\u001b[39m, in \u001b[36mThreadingInstrumentor.__wrap_thread_pool_submit.<locals>.wrapped_func\u001b[39m\u001b[34m(*func_args, **func_kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    170\u001b[39m     token = context.attach(otel_context)\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/models/bedrock.py:743\u001b[39m, in \u001b[36mBedrockModel._stream\u001b[39m\u001b[34m(self, callback, messages, tool_specs, system_prompt, tool_choice)\u001b[39m\n\u001b[32m    734\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m             e.response[\u001b[33m\"\u001b[39m\u001b[33mError\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mValidationException\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    736\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mwith on-demand throughput isnâ€™t supported\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message\n\u001b[32m    737\u001b[39m         ):\n\u001b[32m    738\u001b[39m             e.add_note(\n\u001b[32m    739\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mâ”” For more information see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    740\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mhttps://strandsagents.com/latest/user-guide/concepts/model-providers/amazon-bedrock/#on-demand-throughput-isnt-supported\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    741\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m743\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    746\u001b[39m     callback()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/strands/models/bedrock.py:661\u001b[39m, in \u001b[36mBedrockModel._stream\u001b[39m\u001b[34m(self, callback, messages, tool_specs, system_prompt, tool_choice)\u001b[39m\n\u001b[32m    659\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mgot response from model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverse_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    662\u001b[39m     \u001b[38;5;66;03m# Track tool use events to fix stopReason for streaming responses\u001b[39;00m\n\u001b[32m    663\u001b[39m     has_tool_use = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/botocore/client.py:602\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    600\u001b[39m     )\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/github/gen-ai/strands/strands-agents-samples/.venv/lib/python3.13/site-packages/botocore/client.py:1078\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1074\u001b[39m     error_code = request_context.get(\n\u001b[32m   1075\u001b[39m         \u001b[33m'\u001b[39m\u001b[33merror_code_override\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1076\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1077\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mValidationException\u001b[39m: An error occurred (ValidationException) when calling the ConverseStream operation: Invocation of model ID anthropic.claude-haiku-4-5-20251001-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.",
      "â”” Bedrock region: ap-southeast-2",
      "â”” Model id: anthropic.claude-haiku-4-5-20251001-v1:0",
      "â”” For more information see https://strandsagents.com/latest/user-guide/concepts/model-providers/amazon-bedrock/#on-demand-throughput-isnt-supported"
     ]
    }
   ],
   "source": [
    "# Initialize our agent without a callback handler\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# --- Create the Bedrock model using your inference profile ARN ---\n",
    "   \n",
    "\n",
    "# inference_profile_arn=\"arn:aws:bedrock:ap-southeast-2:381491838394:inference-profile/au.anthropic.claude-haiku-4-5-20251001-v1:0\",\n",
    "    \n",
    "agent = Agent(\n",
    "    # model= \"anthropic.claude-haiku-4-5-20251001-v1:0\"\n",
    "    # model=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",  # Optional: Specify the model ID\n",
    "    model= model,\n",
    "    tools=[calculator], \n",
    "    callback_handler=None)\n",
    "\n",
    "# Async function that iterators over streamed agent events\n",
    "\n",
    "\n",
    "async def process_streaming_response():\n",
    "    agent_stream = agent.stream_async(\"Calculate 2+2\")\n",
    "    async for event in agent_stream:\n",
    "        print(event)\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "asyncio.run(process_streaming_response())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tracking event loop lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrates the event loop lifecycle and how events relate to each other. It's useful for understanding the flow of execution in the Strands Agent:\n",
    "\n",
    "Let's create some printing format code to better analyse the agent stream events. We will continue to use the same agent for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Event loop initialized\n",
      "ğŸ“ New cycle started\n",
      "â–¶ï¸ Event loop cycle starting\n",
      "ğŸ“Ÿ Text: I\n",
      "ğŸ“Ÿ Text:  can help you with\n",
      "ğŸ“Ÿ Text:  the\n",
      "ğŸ“Ÿ Text:  mathematical calcul...\n",
      "ğŸ“Ÿ Text: , but I don\n",
      "ğŸ“Ÿ Text: 't have a\n",
      "ğŸ“Ÿ Text:  tool available\n",
      "ğŸ“Ÿ Text:  to look\n",
      "ğŸ“Ÿ Text:  up geographical\n",
      "ğŸ“Ÿ Text:  information\n",
      "ğŸ“Ÿ Text:  like capitals of\n",
      "ğŸ“Ÿ Text:  countries. Let me\n",
      "ğŸ“Ÿ Text:  calculate \n",
      "ğŸ“Ÿ Text: 42\n",
      "ğŸ“Ÿ Text: +7 for\n",
      "ğŸ“Ÿ Text:  you:\n",
      "ğŸ”§ Using tool: calculator\n",
      "ğŸ”§ Using tool: calculator\n",
      "ğŸ”§ Using tool: calculator\n",
      "ğŸ”§ Using tool: calculator\n",
      "ğŸ“¬ New message created: assistant\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Calculation Result</span><span style=\"color: #000080; text-decoration-color: #000080\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Operation </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> Evaluate Expression </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Input     </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 42+7                </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Result    </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 49                  </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mâ•­â”€\u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mCalculation Result\u001b[0m\u001b[34m \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mOperation\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mEvaluate Expression\u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mInput    \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m42+7               \u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mResult   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m49                 \u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¬ New message created: user\n",
      "ğŸ“ New cycle started\n",
      "ğŸ“ New cycle started\n",
      "â–¶ï¸ Event loop cycle starting\n",
      "ğŸ“Ÿ Text: The result\n",
      "ğŸ“Ÿ Text:  of 42 +\n",
      "ğŸ“Ÿ Text:  7 is\n",
      "ğŸ“Ÿ Text:  49.\n",
      "ğŸ“Ÿ Text: \n",
      "\n",
      "As for the capital...\n",
      "ğŸ“Ÿ Text:  France, while\n",
      "ğŸ“Ÿ Text:  I know it is Paris,...\n",
      "ğŸ“Ÿ Text:  don't have a specif...\n",
      "ğŸ“Ÿ Text:  tool to verify or\n",
      "ğŸ“Ÿ Text:  look up this inform...\n",
      "ğŸ“Ÿ Text:  in the current\n",
      "ğŸ“Ÿ Text:  environment.\n",
      "ğŸ“¬ New message created: assistant\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': [{'text': \"The result of 42 + 7 is 49.\\n\\nAs for the capital of France, while I know it is Paris, I don't have a specific tool to verify or look up this information in the current environment.\"}]}, metrics=EventLoopMetrics(cycle_count=4, tool_metrics={'calculator': ToolMetrics(tool={'toolUseId': 'tooluse_KJZb-ToGQFOM0KIasq7tdw', 'name': 'calculator', 'input': {'expression': '42+7'}}, call_count=2, success_count=2, error_count=0, total_time=0.012037038803100586)}, cycle_durations=[1.2419390678405762, 1.8845319747924805], traces=[<strands.telemetry.metrics.Trace object at 0x77af86530980>, <strands.telemetry.metrics.Trace object at 0x77af8651a2c0>, <strands.telemetry.metrics.Trace object at 0x77af86535150>, <strands.telemetry.metrics.Trace object at 0x77af86ce6d50>], accumulated_usage={'inputTokens': 8226, 'outputTokens': 234, 'totalTokens': 8460}, accumulated_metrics={'latencyMs': 7149}), state={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Async function that iterators over streamed agent events\n",
    "\n",
    "\n",
    "async def process_streaming_response():\n",
    "    agent_stream = agent.stream_async(\"What is the capital of France and what is 42+7?\")\n",
    "    async for event in agent_stream:\n",
    "        # Track event loop lifecycle\n",
    "        if event.get(\"init_event_loop\", False):\n",
    "            print(\"ğŸ”„ Event loop initialized\")\n",
    "        elif event.get(\"start_event_loop\", False):\n",
    "            print(\"â–¶ï¸ Event loop cycle starting\")\n",
    "        elif event.get(\"start\", False):\n",
    "            print(\"ğŸ“ New cycle started\")\n",
    "        elif \"message\" in event:\n",
    "            print(f\"ğŸ“¬ New message created: {event['message']['role']}\")\n",
    "        elif event.get(\"force_stop\", False):\n",
    "            print(\n",
    "                f\"ğŸ›‘ Event loop force-stopped: {event.get('force_stop_reason', 'unknown reason')}\"\n",
    "            )\n",
    "\n",
    "        # Track tool usage\n",
    "        if \"current_tool_use\" in event and event[\"current_tool_use\"].get(\"name\"):\n",
    "            tool_name = event[\"current_tool_use\"][\"name\"]\n",
    "            print(f\"ğŸ”§ Using tool: {tool_name}\")\n",
    "\n",
    "        # Show only a snippet of text to keep output clean\n",
    "        if \"data\" in event:\n",
    "            # Only show first 20 chars of each chunk for demo purposes\n",
    "            data_snippet = event[\"data\"][:20] + (\n",
    "                \"...\" if len(event[\"data\"]) > 20 else \"\"\n",
    "            )\n",
    "            print(f\"ğŸ“Ÿ Text: {data_snippet}\")\n",
    "\n",
    "    return event[\"result\"]\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "asyncio.run(process_streaming_response())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAPI Integration\n",
    "\n",
    "You can also integrate your `stream_async` with FastAPI to create a streaming endpoint to your applications. For this, we will add a `weather_forecast` tool to our agent. The architecture update looks as following\n",
    "\n",
    "<div style=\"text-align:left;\">\n",
    "    <img src=\"./images/architecture_2.png\" width=\"65%\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [338769]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Server is running at http://0.0.0.0:8001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58480 - \"POST /stream HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# # Tool definition\n",
    "from strands.models import BedrockModel\n",
    "model_id = \"anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "model = BedrockModel(\n",
    "    model_id=model_id,\n",
    ")\n",
    "\n",
    "@tool\n",
    "def weather_forecast(city: str, days: int = 3) -> str:\n",
    "    return f\"Weather forecast for {city} for the next {days} days...\"\n",
    "\n",
    "\n",
    "# FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "class PromptRequest(BaseModel):\n",
    "    prompt: str\n",
    "\n",
    "\n",
    "@app.post(\"/stream\")\n",
    "async def stream_response(request: PromptRequest):\n",
    "    async def generate():\n",
    "        agent = Agent( model = model, \n",
    "                      tools=[calculator, weather_forecast], callback_handler=None)\n",
    "        try:\n",
    "            async for event in agent.stream_async(request.prompt):\n",
    "                if \"data\" in event:\n",
    "                    yield event[\"data\"]\n",
    "        except Exception as e:\n",
    "            yield f\"Error: {str(e)}\"\n",
    "\n",
    "    return StreamingResponse(generate(), media_type=\"text/plain\")\n",
    "\n",
    "\n",
    "# Function to start server without blocking\n",
    "\n",
    "\n",
    "async def start_server():\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8001, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()\n",
    "\n",
    "\n",
    "# Run server as background task\n",
    "if \"server_task\" not in globals():\n",
    "    server_task = asyncio.create_task(start_server())\n",
    "    await asyncio.sleep(0.1)  # Give server time to start\n",
    "\n",
    "print(\"âœ… Server is running at http://0.0.0.0:8001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoking the FastAPI agent\n",
    "And we can now invoke the agent with a prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received: I'll check the current weather forecast for New York City.Based on the forecast, this is what we can expect for New York City over the next 3 days. (Note: I'm seeing simulated forecast data in this environment, but I've passed your request through to get the current forecast information.)\n"
     ]
    }
   ],
   "source": [
    "async def fetch_stream():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        async with client.stream(\n",
    "            \"POST\",\n",
    "            \"http://0.0.0.0:8001/stream\",\n",
    "            json={\"prompt\": \"What is weather in NYC?\"},\n",
    "        ) as response:\n",
    "            async for line in response.aiter_lines():\n",
    "                if line.strip():  # Skip empty lines\n",
    "                    print(\"Received:\", line)\n",
    "\n",
    "\n",
    "await fetch_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 - Callback Handlers for streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callback handlers are a powerful feature of the Strands Agents that allow you to intercept and process events as they happen during agent execution. This enables real-time monitoring, custom output formatting, and integration with external systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callback handlers receive events in real-time as they occur during an agent's lifecycle:\n",
    "\n",
    "- Text generation from the model\n",
    "- Tool selection and execution\n",
    "- Reasoning process\n",
    "- Errors and completions\n",
    "\n",
    "\n",
    "Let's now create a custom callback handler function that formats the event inputs to highlight tool usage and model output. To do so, we will again use the agent with a calculator tool only\n",
    "\n",
    "<div style=\"text-align:left;\">\n",
    "    <img src=\"images/architecture.png\" width=\"65%\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT: I\n",
      "MODEL OUTPUT: 'll\n",
      "MODEL OUTPUT:  help you calculate 2\n",
      "MODEL OUTPUT: +2 using\n",
      "MODEL OUTPUT:  the calculator\n",
      "MODEL OUTPUT:  function\n",
      "MODEL OUTPUT:  in evaluate\n",
      "MODEL OUTPUT:  mode.\n",
      "\n",
      "USING TOOL: calculator\n",
      "\n",
      "USING TOOL: calculator\n",
      "\n",
      "USING TOOL: calculator\n",
      "\n",
      "USING TOOL: calculator\n",
      "\n",
      "USING TOOL: calculator\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Calculation Result</span><span style=\"color: #000080; text-decoration-color: #000080\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Operation </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> Evaluate Expression </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Input     </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 2+2                 </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Result    </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 4                   </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mâ•­â”€\u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mCalculation Result\u001b[0m\u001b[34m \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mOperation\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mEvaluate Expression\u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mInput    \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m2+2                \u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mResult   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m4                  \u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT: The\n",
      "MODEL OUTPUT:  result\n",
      "MODEL OUTPUT:  is\n",
      "MODEL OUTPUT:  4.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': [{'text': 'The result is 4.'}]}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={'calculator': ToolMetrics(tool={'toolUseId': 'tooluse_vBmEv_o7R-GxSFY0eXR8mw', 'name': 'calculator', 'input': {'expression': '2+2'}}, call_count=1, success_count=1, error_count=0, total_time=0.004732847213745117)}, cycle_durations=[0.9648020267486572], traces=[<strands.telemetry.metrics.Trace object at 0x77af8537f9d0>, <strands.telemetry.metrics.Trace object at 0x77af7a7e5130>], accumulated_usage={'inputTokens': 3981, 'outputTokens': 82, 'totalTokens': 4063}, accumulated_metrics={'latencyMs': 2699}), state={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_callback_handler(**kwargs):\n",
    "    # Process stream data\n",
    "    if \"data\" in kwargs:\n",
    "        print(f\"MODEL OUTPUT: {kwargs['data']}\")\n",
    "    elif \"current_tool_use\" in kwargs and kwargs[\"current_tool_use\"].get(\"name\"):\n",
    "        print(f\"\\nUSING TOOL: {kwargs['current_tool_use']['name']}\")\n",
    "\n",
    "\n",
    "# Create an agent with custom callback handler\n",
    "agent = Agent(   \n",
    "        model=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",  # Optional: Specify the model ID\n",
    "        tools=[calculator], \n",
    "        callback_handler=custom_callback_handler)\n",
    "\n",
    "agent(\"Calculate 2+2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "In this notebook you learned how to stream your agents outputs using async iteractors and callback handlers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strands-agents-samples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
