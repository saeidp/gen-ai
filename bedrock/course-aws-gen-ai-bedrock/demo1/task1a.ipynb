{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a74f560d-5f6d-443d-a7ec-70b5f64aa48c",
   "metadata": {},
   "source": [
    "# Task 1a: Perform Text Generation\n",
    "\n",
    "In this notebook, you learn how to use Large Language Model (LLM) to generate an email response to a customer who provided negative feedback on the quality of customer service they received from the support engineer. In this notebook, you generate an email with a thank you note based on the customer's previous email. You use the Amazon Titan model using the Amazon Bedrock API with Boto3 client.\n",
    "\n",
    "The prompt used in this task is called a zero-shot prompt. In a zero-shot prompt, you describe the task or desired output to the language model in plain language. The model then uses its pre-trained knowledge and capabilities to generate a response or complete the task based solely on the provided prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc50b7-d3e6-47c1-baeb-576f102c4a3e",
   "metadata": {},
   "source": [
    "#### Scenario\n",
    "You are Bob a Customer Service Manager at AnyCompany and some of your customers are not happy with the customer service and are providing negative feedbacks on the service provided by customer support engineers. Now, you would like to respond to those customers apologizing for the poor service and to regain trust. You need the help of an LLM to generate a bulk of emails for you which are human friendly and personalized to the customer's sentiment from previous email correspondence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a077c8-3f5d-4744-bce3-62870721123b",
   "metadata": {},
   "source": [
    "## Task 1a.1: Environment setup\n",
    "\n",
    "In this task, you set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c224339-614e-4e99-9891-faf1636f1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "session = boto3.Session(profile_name=\"default\")\n",
    "bedrock_client = session.client('bedrock-runtime')\n",
    "\n",
    "# bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1948b10-8bab-4551-a2d4-36e5bb9cb72e",
   "metadata": {},
   "source": [
    "## Task 1a.2: Generate text\n",
    "\n",
    "In this task, you prepare an input for the Amazon Bedrock service to generate an email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd638aa4-2611-4b2d-92c1-a44a3f682488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the prompt\n",
    "prompt_data = \"\"\"\n",
    "Command: Write an email from Bob, Customer Service Manager, AnyCompany to the customer \"John Doe\" \n",
    "who provided negative feedback on the service provided by our customer support \n",
    "engineer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a757039f-9b4c-4b15-9e71-cd9bcb412260",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\n",
    "    \"inputText\": prompt_data, \n",
    "    \"textGenerationConfig\":{\n",
    "        \"maxTokenCount\":8192,\n",
    "        \"stopSequences\":[],\n",
    "        \"temperature\":0,\n",
    "        \"topP\":0.9\n",
    "        }\n",
    "    }) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023832e6-a69e-414b-99f9-844689ff3352",
   "metadata": {},
   "source": [
    "Next, you use the Amazon Titan model.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** Amazon Titan supports a context window of ~4k tokens and accepts the following parameters:\n",
    "- `inputText`: Prompt to the LLM\n",
    "- `textGenerationConfig`: These are the parameters that model will take into account while generating the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3196ec-18ff-4343-acea-5ee7c3e00d26",
   "metadata": {},
   "source": [
    "The Amazon Bedrock API provides you with an API `invoke_model` which accepts the following:\n",
    "- `modelId`: This is the model ARN for the various foundation models available under Amazon Bedrock\n",
    "- `accept`: The type of input request\n",
    "- `contentType`: The content type of the output\n",
    "- `body`: A json string consisting of the prompt and the configurations\n",
    "\n",
    "Refer to [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html) for Available text generation model Ids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9231eada-8ac5-4433-bd35-32e29c02ba4e",
   "metadata": {},
   "source": [
    "## Task 1a.3: Invoke the Amazon Titan Large language model\n",
    "\n",
    "In this task, you explore how the model generates an output based on the prompt created earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2ba19c-9824-4cb1-a1ad-bcb4270c8c4d",
   "metadata": {},
   "source": [
    "### Complete Output Generation\n",
    "\n",
    "This email is generated using the Amazon Titan model by understanding the input request and utilizing its inherent understanding of different modalities. The request to the API is synchronous and waits for the entire output to be generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acfecd6c-14f6-4656-bfa4-d0e39fe7dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke model\n",
    "modelId = 'amazon.titan-text-express-v1' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "outputText = \"\\n\"\n",
    "try:\n",
    "\n",
    "    response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    outputText = response_body.get('results')[0].get('outputText')\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    \n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add7ad6c-988a-4737-80e2-e167a84e4b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Apology for the negative experience you had with our customer support engineer\n",
      "\n",
      "Dear John Doe,\n",
      "\n",
      "I am writing to express my deepest apologies for the negative experience you had with our customer support engineer.\n",
      "\n",
      "We take customer feedback very seriously and I want to assure you that we are taking steps to prevent this from happening again. Our customer support engineer has been reprimanded for their behavior and we have provided additional training to prevent similar issues in the future.\n",
      "\n",
      "In addition, we would like to make it up to you for the negative experience you had. We would like to offer you a $50 gift card to use on your next purchase with us.\n",
      "\n",
      "Please accept our apologies once again for the negative experience you had with our customer support engineer.\n",
      "\n",
      "Sincerely,\n",
      "Bob\n",
      "Customer Service Manager\n",
      "AnyCompany\n"
     ]
    }
   ],
   "source": [
    "# The relevant portion of the response begins after the first newline character\n",
    "# Below we print the response beginning after the first occurence of '\\n'.\n",
    "\n",
    "email = outputText[outputText.index('\\n')+1:]\n",
    "print(email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f9081-902e-48d1-ab91-801216f08d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bedrock)",
   "language": "python",
   "name": "bedrock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
